{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04adbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_predictions():\n",
    "    # 1. Load the Test Data\n",
    "    # We use literal_eval to parse the stringified list of answers (e.g., \"['opt1', 'opt2']\")\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "    test_df['answers'] = test_df['answers'].apply(literal_eval)\n",
    "    \n",
    "    print(f\"Loaded {len(test_df)} test examples.\")\n",
    "\n",
    "    # 2. Load Model and Tokenizer\n",
    "    # The model is a Sequence Classifier (NLI). Label 1 usually corresponds to Entailment/True.\n",
    "    model_name = \"qbao775/AMR-LE-DeBERTa-V2-XXLarge-Contraposition-Double-Negation-Implication-Commutative-Pos-Neg-1-3\"\n",
    "    \n",
    "    print(\"Loading model... (this may take a while for XXLarge)\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    \n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # 3. Inference Loop\n",
    "    # Iterate through each question in the test set\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Inference\"):\n",
    "        context = row['context']\n",
    "        question = row['question']\n",
    "        options = row['answers']\n",
    "        \n",
    "        # Construct the premise (Context + Question)\n",
    "        # We ensure a space exists between context and question\n",
    "        premise = f\"{context} {question}\"\n",
    "        \n",
    "        # Prepare inputs for all options for this single question\n",
    "        # We create a batch where each item is a pair: (Premise, Option)\n",
    "        encoded_inputs = tokenizer(\n",
    "            [premise] * len(options),  # Repeat premise for each option\n",
    "            options,                   # The list of options (hypotheses)\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,            # DeBERTa limit\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to GPU\n",
    "        inputs = {k: v.to(device) for k, v in encoded_inputs.items()}\n",
    "        \n",
    "        # Run the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits  # Shape: (num_options, 2)\n",
    "        \n",
    "        # 4. Select the Best Answer\n",
    "        # The model outputs 2 scores per pair: [Logits_False, Logits_True]\n",
    "        # We want the option with the highest score for 'True' (Index 1)\n",
    "        \n",
    "        # Extract the column for label 1 (Entailment/Equivalence)\n",
    "        entailment_scores = logits[:, 1]\n",
    "        \n",
    "        # Find the index of the option with the highest entailment score\n",
    "        best_option_idx = torch.argmax(entailment_scores).item()\n",
    "        predictions.append(best_option_idx)\n",
    "\n",
    "    # 5. Save Predictions\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'label': predictions\n",
    "    })\n",
    "    \n",
    "    output_filename = \"submission.csv\"\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Predictions saved to {output_filename}\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c940c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738c5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c336efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
