{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2c447",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMultipleChoice, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    PreTrainedTokenizerBase\n",
    ")\n",
    "from transformers.tokenization_utils_base import PaddingStrategy\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Configuration & Hyperparameters (Ref: ReClor Paper Table 9)\n",
    "# -----------------------------------------------------------------------------\n",
    "MODEL_ID = \"FacebookAI/roberta-large\"\n",
    "TRAIN_FILE = \"train.json\"\n",
    "VAL_FILE = \"val.json\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "OUTPUT_DIR = \"./reclor_roberta_large_finetuned\"\n",
    "\n",
    "# Paper settings for RoBERTa-Large\n",
    "MAX_SEQ_LENGTH = 256\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "ADAM_EPSILON = 1e-6\n",
    "ADAM_BETAS = (0.9, 0.98)\n",
    "\n",
    "# Batch size handling\n",
    "PER_DEVICE_BATCH_SIZE = 2   # Adjust based on your VRAM (2 fits most Colab GPUs)\n",
    "EFFECTIVE_BATCH_SIZE = 24   # As per paper\n",
    "GRAD_ACCUMULATION = EFFECTIVE_BATCH_SIZE // PER_DEVICE_BATCH_SIZE\n",
    "\n",
    "# Validation set target size (standard ReClor Val size is 500)\n",
    "TARGET_VAL_SIZE = 500\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Data Preprocessing & Collator\n",
    "# -----------------------------------------------------------------------------\n",
    "def preprocess_function(examples):\n",
    "    # ReClor structure: Context + Question + [Option 0...3]\n",
    "    first_sentences = [[context] * 4 for context in examples[\"context\"]]\n",
    "    question_headers = examples[\"question\"]\n",
    "    \n",
    "    second_sentences = []\n",
    "    for i, header in enumerate(question_headers):\n",
    "        options = examples[\"answers\"][i]\n",
    "        \n",
    "        # Robust parsing for stringified lists\n",
    "        if isinstance(options, str):\n",
    "            try:\n",
    "                options = ast.literal_eval(options)\n",
    "            except:\n",
    "                options = [\"\", \"\", \"\", \"\"] \n",
    "\n",
    "        second_sentences.append([f\"{header} {option}\" for option in options])\n",
    "\n",
    "    # Flatten\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        padding=False, \n",
    "    )\n",
    "\n",
    "    # Un-flatten\n",
    "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features] if label_name in features[0].keys() else None\n",
    "        \n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        \n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        \n",
    "        if labels is not None:\n",
    "            batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "            \n",
    "        return batch\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Main Execution\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- Load Tokenizer ---\n",
    "    print(f\"Loading tokenizer from {MODEL_ID}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "    # --- Load Local Data ---\n",
    "    print(f\"Loading datasets...\")\n",
    "    data_files = {\"train\": TRAIN_FILE, \"validation\": VAL_FILE}\n",
    "    dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP A: Remove Data Leakage\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"Checking for data leakage (overlapping questions in Test set)...\")\n",
    "    \n",
    "    test_df_ref = pd.read_csv(TEST_FILE)\n",
    "    # Create signature tuple (context, question) for unique identification\n",
    "    test_signatures = set(zip(test_df_ref['context'].str.strip(), test_df_ref['question'].str.strip()))\n",
    "    \n",
    "    print(f\"Test set contains {len(test_signatures)} unique context/question pairs.\")\n",
    "\n",
    "    def filter_leakage(example):\n",
    "        c = example['context'].strip()\n",
    "        q = example['question'].strip()\n",
    "        # Keep example only if it is NOT in the test signatures\n",
    "        return (c, q) not in test_signatures\n",
    "\n",
    "    # Store original sizes\n",
    "    orig_train_len = len(dataset['train'])\n",
    "    orig_val_len = len(dataset['validation'])\n",
    "    \n",
    "    # Apply filter\n",
    "    dataset = dataset.filter(filter_leakage)\n",
    "    \n",
    "    print(f\"Train filtered: {orig_train_len} -> {len(dataset['train'])} (Removed {orig_train_len - len(dataset['train'])})\")\n",
    "    print(f\"Val filtered:   {orig_val_len} -> {len(dataset['validation'])} (Removed {orig_val_len - len(dataset['validation'])})\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP B: Rebalance Validation Set (if too small)\n",
    "    # -------------------------------------------------------------------------\n",
    "    current_val_len = len(dataset['validation'])\n",
    "    \n",
    "    if current_val_len < TARGET_VAL_SIZE:\n",
    "        needed = TARGET_VAL_SIZE - current_val_len\n",
    "        print(f\"\\nValidation set is below target ({current_val_len} < {TARGET_VAL_SIZE}).\")\n",
    "        print(f\"Transferring {needed} samples from Training to Validation...\")\n",
    "        \n",
    "        # Ensure we don't drain the training set completely\n",
    "        if needed > len(dataset['train']) * 0.2:\n",
    "            print(\"Warning: Requested transfer is large relative to training set. Capping transfer.\")\n",
    "            needed = int(len(dataset['train']) * 0.2)\n",
    "            \n",
    "        # Split the training set\n",
    "        # We use a fixed seed for reproducibility\n",
    "        split_data = dataset['train'].train_test_split(test_size=needed, seed=42)\n",
    "        \n",
    "        new_train_set = split_data['train']\n",
    "        moved_samples = split_data['test']\n",
    "        \n",
    "        # Combine existing val with moved samples\n",
    "        new_val_set = concatenate_datasets([dataset['validation'], moved_samples])\n",
    "        \n",
    "        # Update main dataset object\n",
    "        dataset['train'] = new_train_set\n",
    "        dataset['validation'] = new_val_set\n",
    "        \n",
    "        print(f\"Rebalancing Complete.\")\n",
    "        print(f\"Final Train Size: {len(dataset['train'])}\")\n",
    "        print(f\"Final Val Size:   {len(dataset['validation'])}\")\n",
    "    else:\n",
    "        print(\"\\nValidation set size is sufficient.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Training\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\nPreprocessing datasets for training...\")\n",
    "    tokenized_reclor = dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    print(f\"Loading {MODEL_ID} for Multiple Choice...\")\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(MODEL_ID)\n",
    "    model.to(device)\n",
    "\n",
    "    # Paper Specs via TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        eval_strategy=\"epoch\", \n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=PER_DEVICE_BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        adam_epsilon=ADAM_EPSILON,\n",
    "        adam_beta1=ADAM_BETAS[0],\n",
    "        adam_beta2=ADAM_BETAS[1],\n",
    "        max_grad_norm=None, \n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        logging_steps=50,\n",
    "        fp16=torch.cuda.is_available(), \n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_reclor[\"train\"],\n",
    "        eval_dataset=tokenized_reclor[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(f\"Saving best model to {OUTPUT_DIR}...\")\n",
    "    trainer.save_model(OUTPUT_DIR)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Inference\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"\\nLoading test data from {TEST_FILE}...\")\n",
    "    test_df = pd.read_csv(TEST_FILE)\n",
    "    \n",
    "    test_df['answers'] = test_df['answers'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    test_df['label'] = 0 \n",
    "    \n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    \n",
    "    print(\"Preprocessing test data...\")\n",
    "    tokenized_test = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    print(\"Running predictions...\")\n",
    "    predictions_output = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(predictions_output.predictions, axis=1)\n",
    "\n",
    "    # Save Submission\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"label\": preds\n",
    "    })\n",
    "    \n",
    "    submission_file = \"submission.csv\"\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"Done! Predictions saved to {submission_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
